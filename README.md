# finetune-gptneo
Fine Tune GPT-NEO (2.7B and 1.3B Parameters) on a single GPU with Huggingface Transformers using DeepSpeed.
